"""
MoEæŸå¤±å‡½æ•°æ¨¡å— - åŒ…å«æ‰€æœ‰è‡ªå®šä¹‰æŸå¤±å‡½æ•°
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, Optional, Union


def compute_all_metrics(y_true, y_pred):
    """è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡"""
    y_true = np.array(y_true).flatten()
    y_pred = np.array(y_pred).flatten()
    
    # åŸºç¡€æŒ‡æ ‡
    mse = np.mean((y_true - y_pred) ** 2)
    rmse = np.sqrt(mse)
    mae = np.mean(np.abs(y_true - y_pred))
    
    # ç›¸å…³ç³»æ•°
    correlation = np.corrcoef(y_true, y_pred)[0, 1] if len(y_true) > 1 else 0
    
    # RÂ²
    ss_res = np.sum((y_true - y_pred) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
    
    # KGEæŒ‡æ ‡è®¡ç®—
    bias = np.mean(y_pred) - np.mean(y_true)
    alpha = np.std(y_pred) / np.std(y_true) if np.std(y_true) > 0 else 0
    beta = np.mean(y_pred) / np.mean(y_true) if np.mean(y_true) > 0 else 0
    
    kge = 1 - np.sqrt((correlation - 1)**2 + (alpha - 1)**2 + (beta - 1)**2)
    
    return {
        'mse': mse,
        'rmse': rmse,
        'mae': mae,
        'r2': r2,
        'correlation': correlation,
        'kge': kge,
        'bias': bias,
        'alpha': alpha,
        'beta': beta
    }


def format_metrics_string(metrics):
    """æ ¼å¼åŒ–æŒ‡æ ‡å­—ç¬¦ä¸²"""
    return f"RÂ²: {metrics['r2']:.4f}, KGE: {metrics['kge']:.4f}, RMSE: {metrics['rmse']:.4f}"


class HydroKGELoss(nn.Module):
    """
    æ°´æ–‡KGEæŸå¤±å‡½æ•°ï¼Œç»“åˆå‡æ–¹è¯¯å·®ã€ç»å¯¹è¯¯å·®å’Œè´Ÿè½½å‡è¡¡
    """
    
    def __init__(self, mse_weight=0.8, l1_weight=0.2, load_balance_weight=0.0):
        super().__init__()
        self.mse_weight = mse_weight
        self.l1_weight = l1_weight
        self.load_balance_weight = load_balance_weight
        self.mse_loss = nn.MSELoss()
        self.l1_loss = nn.L1Loss()
        
    def forward(self, predictions, targets, gate_info=None):
        """
        è®¡ç®—æ··åˆæŸå¤±
        
        Args:
            predictions: æ¨¡å‹é¢„æµ‹å€¼ [batch_size, ...]
            targets: çœŸå®ç›®æ ‡å€¼ [batch_size, ...]
            gate_info: é—¨æ§ä¿¡æ¯ï¼Œç”¨äºè´Ÿè½½å‡è¡¡æŸå¤±
        """
        # åŸºç¡€å›å½’æŸå¤±
        mse_loss = self.mse_loss(predictions, targets)
        l1_loss = self.l1_loss(predictions, targets)
        
        # ç»„åˆå›å½’æŸå¤±
        regression_loss = self.mse_weight * mse_loss + self.l1_weight * l1_loss
        
        # è´Ÿè½½å‡è¡¡æŸå¤±
        load_balance_loss = 0.0
        if gate_info is not None and self.load_balance_weight > 0:
            load_balance_loss = self._compute_load_balance_loss(gate_info)
        
        # æ€»æŸå¤±
        total_loss = regression_loss + self.load_balance_weight * load_balance_loss
        
        return total_loss
    
    def _compute_load_balance_loss(self, gate_info):
        """è®¡ç®—è´Ÿè½½å‡è¡¡æŸå¤±"""
        total_loss = 0.0
        count = 0
        
        for module_name, module_gate_info in gate_info.items():
            if 'gate_weights' in module_gate_info:
                gate_weights = module_gate_info['gate_weights']  # [batch_size, num_experts]
                
                # å¦‚å¯ç”¨ï¼Œè®¡ç®—ä½¿ç”¨é¢‘ç‡ä¸å‡åŒ€åˆ†å¸ƒçš„å·®å¼‚ï¼ˆé»˜è®¤ä¸å¯ç”¨ï¼‰
                expert_usage = torch.mean(gate_weights, dim=0)
                target_usage = 1.0 / len(expert_usage)
                balance_loss = torch.mean((expert_usage - target_usage) ** 2)
                total_loss += balance_loss
                count += 1
        
        return total_loss / count if count > 0 else torch.tensor(0.0, device=gate_weights.device)


class StationR2Loss(nn.Module):
    """
    åŸºäºç«™ç‚¹RÂ²çš„æŸå¤±å‡½æ•°
    """
    
    def __init__(self, min_r2: float = -1.0, max_r2: float = 1.0, min_samples_per_station: int = 5):
        super().__init__()
        self.min_r2 = min_r2
        self.max_r2 = max_r2
        self.min_samples_per_station = min_samples_per_station
    
    def forward(self, predictions, targets, station_ids=None):
        """
        è®¡ç®—ç«™ç‚¹çº§RÂ²æŸå¤±
        
        Args:
            predictions: é¢„æµ‹å€¼ [batch_size]
            targets: çœŸå®å€¼ [batch_size]
            station_ids: ç«™ç‚¹ID [batch_size], å¯é€‰
        """
        # ç»Ÿä¸€å±•å¹³åˆ°1Dï¼Œå…¼å®¹ [B] ä¸ [B,1] æƒ…å†µ
        predictions = predictions.view(-1)
        targets = targets.view(-1)
        if station_ids is None:
            station_ids = torch.zeros_like(predictions, dtype=torch.long)
        else:
            station_ids = station_ids.view(-1)
        # å¯¹é½é•¿åº¦ï¼ˆå–æœ€å°é•¿åº¦ä»¥é˜²ä¸ä¸€è‡´ï¼‰
        n = min(predictions.shape[0], targets.shape[0], station_ids.shape[0])
        predictions = predictions[:n]
        targets = targets[:n]
        station_ids = station_ids[:n]
        
        unique_stations = torch.unique(station_ids)
        total_loss = torch.tensor(0.0, device=predictions.device, requires_grad=True)
        
        for station_id in unique_stations:
            # è·å–è¯¥ç«™ç‚¹çš„æ•°æ®
            mask = station_ids == station_id
            if mask.ndim != 1:
                mask = mask.view(-1)
            if mask.sum() == 0:
                continue
            station_preds = predictions[mask]
            station_targets = targets[mask]
            
            if len(station_preds) < self.min_samples_per_station:
                # æ ·æœ¬å¤ªå°‘æ—¶ï¼Œä½¿ç”¨MSEä½œä¸ºç¨³å®šå›é€€ï¼Œé¿å…RÂ²æ•°å€¼ä¸ç¨³å®š
                station_loss = torch.mean((station_targets - station_preds) ** 2)
                total_loss = total_loss + station_loss
                continue
                
            # è®¡ç®—RÂ²
            ss_res = torch.sum((station_targets - station_preds) ** 2)
            ss_tot = torch.sum((station_targets - torch.mean(station_targets)) ** 2)
            
            if ss_tot > 1e-8:
                r2 = 1 - (ss_res / ss_tot)
                # é™åˆ¶RÂ²èŒƒå›´ï¼Œé¿å…æç«¯å€¼
                r2 = torch.clamp(r2, self.min_r2, self.max_r2)
                # å°†RÂ²è½¬æ¢ä¸ºæŸå¤±ï¼ˆ1-RÂ²ï¼ŒRÂ²è¶Šé«˜æŸå¤±è¶Šä½ï¼‰
                station_loss = 1 - r2
            else:
                # å½“targetsæ–¹å·®è¿‡å°æ—¶ï¼Œä½¿ç”¨MSEæŸå¤±ä½œä¸ºå›é€€ï¼ˆä¿æŒæ¢¯åº¦ï¼‰
                station_loss = torch.mean((station_targets - station_preds) ** 2)
            
            total_loss = total_loss + station_loss
        
        if len(unique_stations) > 0:
            return total_loss / len(unique_stations)
        else:
            # ç¡®ä¿è¿”å›å¯å¾®åˆ†çš„å¼ é‡ - ä½¿ç”¨é¢„æµ‹å€¼çš„MSEä½œä¸ºå›é€€
            return torch.mean((predictions - targets) ** 2)


class CombinedHydroLoss(nn.Module):
    """
    ç»„åˆæ°´æ–‡æŸå¤±å‡½æ•°ï¼Œç»“åˆMSEã€ç«™ç‚¹RÂ²å’Œè´Ÿè½½å‡è¡¡
    """
    
    def __init__(self, mse_weight=0.5, r2_weight=0.4, load_balance_weight=0.0):
        super().__init__()
        self.mse_weight = mse_weight
        self.r2_weight = r2_weight
        self.load_balance_weight = load_balance_weight
        
        self.mse_loss = nn.MSELoss()
        self.r2_loss = StationR2Loss()
        self.kge_loss = HydroKGELoss(load_balance_weight=0.0)  # ä¸é‡å¤è®¡ç®—è´Ÿè½½å‡è¡¡
    
    def forward(self, predictions, targets, gate_info=None, station_ids=None):
        """
        è®¡ç®—ç»„åˆæŸå¤±
        """
        # MSEæŸå¤±
        mse_loss = self.mse_loss(predictions, targets)
        
        # ç«™ç‚¹RÂ²æŸå¤±
        r2_loss = self.r2_loss(predictions, targets, station_ids)
        
        # è´Ÿè½½å‡è¡¡æŸå¤±
        load_balance_loss = 0.0
        if gate_info is not None and self.load_balance_weight > 0:
            load_balance_loss = self.kge_loss._compute_load_balance_loss(gate_info)
        
        # ç»„åˆæŸå¤±
        total_loss = (self.mse_weight * mse_loss + 
                     self.r2_weight * r2_loss + 
                     self.load_balance_weight * load_balance_loss)
        
        return total_loss


class WeightedHydroLoss(nn.Module):
    """
    åŠ æƒæ°´æ–‡æŸå¤±å‡½æ•° - é‡è§†é«˜å¾„æµäº‹ä»¶
    """

    def __init__(self, base_loss='mse', high_flow_threshold=2.0, high_flow_weight=3.0,
                 extreme_flow_threshold=4.0, extreme_flow_weight=5.0):
        """
        åˆå§‹åŒ–åŠ æƒæŸå¤±å‡½æ•°

        Args:
            base_loss: åŸºç¡€æŸå¤±å‡½æ•°ç±»å‹ ('mse', 'huber')
            high_flow_threshold: é«˜å¾„æµé˜ˆå€¼ï¼ˆæ ‡å‡†åŒ–åï¼‰
            high_flow_weight: é«˜å¾„æµæƒé‡
            extreme_flow_threshold: æç«¯å¾„æµé˜ˆå€¼ï¼ˆæ ‡å‡†åŒ–åï¼‰
            extreme_flow_weight: æç«¯å¾„æµæƒé‡
        """
        super().__init__()
        self.high_flow_threshold = high_flow_threshold
        self.high_flow_weight = high_flow_weight
        self.extreme_flow_threshold = extreme_flow_threshold
        self.extreme_flow_weight = extreme_flow_weight

        if base_loss == 'mse':
            self.base_criterion = nn.MSELoss(reduction='none')
        elif base_loss == 'huber':
            self.base_criterion = nn.SmoothL1Loss(reduction='none', beta=1.0)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„åŸºç¡€æŸå¤±å‡½æ•°: {base_loss}")

    def forward(self, predictions, targets, gate_info=None):
        """
        è®¡ç®—åŠ æƒæŸå¤± - ä¼˜åŒ–ç‰ˆæœ¬
        """
        # ğŸš€ ä¼˜åŒ–ï¼šç®€åŒ–æœ‰æ•ˆæ€§æ£€æŸ¥ï¼Œå‡å°‘é‡å¤æ“ä½œ
        if not (torch.isfinite(predictions).all() and torch.isfinite(targets).all()):
            return torch.tensor(0.0, device=predictions.device, requires_grad=True)

        # è®¡ç®—åŸºç¡€æŸå¤±
        base_loss = self.base_criterion(predictions, targets)

        # ğŸš€ ä¼˜åŒ–ï¼šæå‰æ£€æŸ¥å¹¶è¿”å›
        if not torch.isfinite(base_loss).all():
            return torch.tensor(0.0, device=predictions.device, requires_grad=True)

        # ğŸš€ ä¼˜åŒ–ï¼šç®€åŒ–æƒé‡è®¡ç®—ï¼Œä½¿ç”¨inplaceæ“ä½œ
        target_std = torch.std(targets)
        target_mean = torch.mean(targets)
        
        high_threshold = target_mean + target_std
        extreme_threshold = target_mean + 2.0 * target_std

        # ğŸš€ ä¼˜åŒ–ï¼šç›´æ¥è®¡ç®—åŠ æƒæŸå¤±ï¼Œé¿å…åˆ›å»ºweightså¼ é‡
        high_mask = targets > high_threshold
        extreme_mask = targets > extreme_threshold
        
        weighted_loss = base_loss.clone()
        weighted_loss[high_mask] *= 1.5
        weighted_loss[extreme_mask] *= 2.0

        # é™åˆ¶æŸå¤±èŒƒå›´
        final_loss = torch.clamp(weighted_loss.mean(), max=100.0)

        return final_loss


class AdaptiveHydroLoss(nn.Module):
    """
    è‡ªé€‚åº”æ°´æ–‡æŸå¤±å‡½æ•° - æ ¹æ®å¾„æµé‡çº§åŠ¨æ€è°ƒæ•´æƒé‡
    """

    def __init__(self, alpha=0.5, beta=0.3, gamma=0.2):
        """
        åˆå§‹åŒ–è‡ªé€‚åº”æŸå¤±å‡½æ•°

        Args:
            alpha: MSEæŸå¤±æƒé‡
            beta: ç›¸å¯¹è¯¯å·®æŸå¤±æƒé‡
            gamma: å³°å€¼ä¿æŒæŸå¤±æƒé‡
        """
        super().__init__()
        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        self.mse_loss = nn.MSELoss(reduction='none')

    def forward(self, predictions, targets, gate_info=None):
        """
        è®¡ç®—è‡ªé€‚åº”æŸå¤± - æ•°å€¼ç¨³å®šç‰ˆæœ¬
        """
        # æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
        if torch.isnan(predictions).any() or torch.isinf(predictions).any():
            return torch.tensor(0.0, device=predictions.device, requires_grad=True)
        if torch.isnan(targets).any() or torch.isinf(targets).any():
            return torch.tensor(0.0, device=predictions.device, requires_grad=True)

        # 1. MSEæŸå¤±
        mse_loss = self.mse_loss(predictions, targets)

        # æ£€æŸ¥MSEæŸå¤±
        if torch.isnan(mse_loss).any() or torch.isinf(mse_loss).any():
            return torch.tensor(0.0, device=predictions.device, requires_grad=True)

        # 2. ç›¸å¯¹è¯¯å·®æŸå¤±ï¼ˆå¯¹å°å¾„æµå€¼æ›´æ•æ„Ÿï¼‰- æ›´ä¿å®ˆçš„è®¡ç®—
        epsilon = 1e-3  # å¢å¤§epsilonï¼Œæé«˜æ•°å€¼ç¨³å®šæ€§
        denominator = torch.abs(targets) + epsilon
        relative_error = torch.abs(predictions - targets) / denominator
        relative_error = torch.clamp(relative_error, max=10.0)  # é™åˆ¶ç›¸å¯¹è¯¯å·®
        relative_loss = relative_error ** 2

        # 3. å³°å€¼ä¿æŒæŸå¤±ï¼ˆå¯¹é«˜å¾„æµå€¼æ›´æ•æ„Ÿï¼‰- æ›´ä¿å®ˆçš„ç­–ç•¥
        try:
            peak_threshold = torch.quantile(targets, 0.95)  # æ”¹ä¸ºå‰5%ï¼Œæ›´ä¿å®ˆ
            peak_mask = targets > peak_threshold
            peak_loss = torch.zeros_like(mse_loss)
            if peak_mask.any():
                peak_loss[peak_mask] = mse_loss[peak_mask] * 1.2  # é™ä½å³°å€¼æƒé‡
        except:
            peak_loss = torch.zeros_like(mse_loss)

        # ç»„åˆæŸå¤± - é™ä½å„åˆ†é‡æƒé‡
        total_loss = (self.alpha * mse_loss +
                     self.beta * 0.1 * relative_loss +  # å¤§å¹…é™ä½ç›¸å¯¹è¯¯å·®æƒé‡
                     self.gamma * 0.1 * peak_loss)      # å¤§å¹…é™ä½å³°å€¼æƒé‡

        # é€‚åº¦é™åˆ¶æŸå¤±èŒƒå›´ï¼Œä¸è¦å¤ªä¸¥æ ¼
        final_loss = total_loss.mean()
        final_loss = torch.clamp(final_loss, max=100.0)  # æ”¾å®½é™åˆ¶

        return final_loss


class ExpertSpecializationLoss(nn.Module):
    """
    ä¸“å®¶ä¸“ä¸šåŒ–æŸå¤± - é¼“åŠ±ä¸“å®¶å·®å¼‚åŒ–ï¼Œé¿å…è¶‹åŒ
    """
    
    def __init__(self, diversity_weight: float = 0.01, min_specialization: float = 0.6):
        super().__init__()
        self.diversity_weight = diversity_weight
        self.min_specialization = min_specialization
    
    def forward(self, gate_info: Dict) -> torch.Tensor:
        """
        è®¡ç®—ä¸“å®¶ä¸“ä¸šåŒ–æŸå¤±
        
        Args:
            gate_info: é—¨æ§ä¿¡æ¯ï¼ŒåŒ…å«å„æ¨¡å—çš„é—¨æ§æƒé‡
        
        Returns:
            ä¸“ä¸šåŒ–æŸå¤±ï¼ˆè¶Šä½è¡¨ç¤ºä¸“å®¶è¶Šä¸“ä¸šåŒ–ï¼‰
        """
        total_diversity_loss = torch.tensor(0.0)
        count = 0
        
        if gate_info and isinstance(gate_info, dict):
            module_gates = gate_info.get('module_gates', {})
            
            for module_name, module_info in module_gates.items():
                if 'effective_gate' in module_info:
                    weights = module_info['effective_gate']  # [batch_size, num_experts]
                    
                    # è®¡ç®—ä¸“å®¶ä¸“ä¸šåŒ–ç¨‹åº¦ï¼ˆæƒé‡æ–¹å·®ï¼‰
                    # æƒé‡æ–¹å·®è¶Šå¤§ï¼Œè¯´æ˜ä¸“å®¶è¶Šä¸“ä¸šåŒ–
                    weight_variance = torch.var(weights, dim=-1)  # [batch_size]
                    
                    # é¼“åŠ±é«˜æ–¹å·®ï¼ˆä¸“ä¸šåŒ–ï¼‰ï¼Œæƒ©ç½šä½æ–¹å·®ï¼ˆè¶‹åŒï¼‰
                    # ç›®æ ‡ï¼šæ¯ä¸ªæ ·æœ¬è‡³å°‘æœ‰ä¸€ä¸ªä¸“å®¶æƒé‡ > min_specialization
                    max_weight_per_sample = torch.max(weights, dim=-1)[0]  # [batch_size]
                    specialization_penalty = F.relu(self.min_specialization - max_weight_per_sample)
                    
                    diversity_loss = specialization_penalty.mean()
                    total_diversity_loss += diversity_loss
                    count += 1
        
        return total_diversity_loss / max(count, 1) * self.diversity_weight


class EnhancedCombinedLoss(nn.Module):
    """
    å¢å¼ºç»„åˆæŸå¤±å‡½æ•° - é›†æˆå¤šç§æŸå¤±ç­–ç•¥
    """

    def __init__(self, mse_weight=0.4, kge_weight=0.3, weighted_weight=0.2, adaptive_weight=0.1):
        super().__init__()
        self.mse_weight = mse_weight
        self.kge_weight = kge_weight
        self.weighted_weight = weighted_weight
        self.adaptive_weight = adaptive_weight

        self.mse_loss = nn.MSELoss()
        self.kge_loss = HydroKGELoss(load_balance_weight=0.0)
        self.weighted_loss = WeightedHydroLoss()
        self.adaptive_loss = AdaptiveHydroLoss()
        
        # ğŸš€ æ·»åŠ ä¸“å®¶ä¸“ä¸šåŒ–æŸå¤±
        self.specialization_loss = ExpertSpecializationLoss()

    def forward(self, predictions, targets, gate_info=None, station_ids=None):
        """
        è®¡ç®—å¢å¼ºç»„åˆæŸå¤± - æ•°å€¼ç¨³å®šç‰ˆæœ¬
        """
        # æ£€æŸ¥è¾“å…¥æœ‰æ•ˆæ€§
        if torch.isnan(predictions).any() or torch.isinf(predictions).any():
            return torch.tensor(0.0, device=predictions.device, requires_grad=True)
        if torch.isnan(targets).any() or torch.isinf(targets).any():
            return torch.tensor(0.0, device=predictions.device, requires_grad=True)

        # å„ç§æŸå¤±åˆ†é‡ - æ·»åŠ å¼‚å¸¸å¤„ç†
        try:
            mse_loss = self.mse_loss(predictions, targets)
            if torch.isnan(mse_loss) or torch.isinf(mse_loss):
                mse_loss = torch.tensor(0.0, device=predictions.device)
        except:
            mse_loss = torch.tensor(0.0, device=predictions.device)

        try:
            kge_loss = self.kge_loss(predictions, targets, gate_info)
            if torch.isnan(kge_loss) or torch.isinf(kge_loss):
                kge_loss = torch.tensor(0.0, device=predictions.device)
        except:
            kge_loss = torch.tensor(0.0, device=predictions.device)

        try:
            weighted_loss = self.weighted_loss(predictions, targets)
            if torch.isnan(weighted_loss) or torch.isinf(weighted_loss):
                weighted_loss = torch.tensor(0.0, device=predictions.device)
        except:
            weighted_loss = torch.tensor(0.0, device=predictions.device)

        try:
            adaptive_loss = self.adaptive_loss(predictions, targets)
            if torch.isnan(adaptive_loss) or torch.isinf(adaptive_loss):
                adaptive_loss = torch.tensor(0.0, device=predictions.device)
        except:
            adaptive_loss = torch.tensor(0.0, device=predictions.device)

        # ğŸš€ è®¡ç®—ä¸“å®¶ä¸“ä¸šåŒ–æŸå¤±
        try:
            specialization_loss = self.specialization_loss(gate_info)
            if torch.isnan(specialization_loss) or torch.isinf(specialization_loss):
                specialization_loss = torch.tensor(0.0, device=predictions.device)
        except:
            specialization_loss = torch.tensor(0.0, device=predictions.device)

        # ç»„åˆæŸå¤± - æ›´ä¿å®ˆçš„æƒé‡ + ä¸“ä¸šåŒ–é¼“åŠ±
        total_loss = (0.6 * mse_loss +           # æé«˜MSEæƒé‡ï¼Œæ›´ç¨³å®š
                     0.2 * kge_loss +            # é™ä½KGEæƒé‡
                     0.1 * weighted_loss +       # é™ä½åŠ æƒæŸå¤±æƒé‡
                     0.1 * adaptive_loss -       # é™ä½è‡ªé€‚åº”æŸå¤±æƒé‡
                     0.01 * specialization_loss) # ğŸš€ å‡å»ä¸“ä¸šåŒ–æŸå¤±ï¼ˆé¼“åŠ±ä¸“ä¸šåŒ–ï¼‰

        # é€‚åº¦é™åˆ¶æŸå¤±èŒƒå›´
        total_loss = torch.clamp(total_loss, max=50.0)  # æ”¾å®½é™åˆ¶

        return total_loss


# æŸå¤±å‡½æ•°å·¥å‚
def create_loss_function(loss_type: str, **kwargs) -> nn.Module:
    """
    åˆ›å»ºæŸå¤±å‡½æ•°

    Args:
        loss_type: æŸå¤±å‡½æ•°ç±»å‹ ('mse', 'kge', 'station_r2', 'combined', 'weighted', 'adaptive', 'enhanced')
        **kwargs: æŸå¤±å‡½æ•°å‚æ•°
    """
    if loss_type.lower() == 'mse':
        return nn.MSELoss()
    elif loss_type.lower() == 'kge':
        return HydroKGELoss(**kwargs)
    elif loss_type.lower() == 'station_r2':
        return StationR2Loss(**kwargs)
    elif loss_type.lower() == 'combined':
        return CombinedHydroLoss(**kwargs)
    elif loss_type.lower() == 'weighted':
        return WeightedHydroLoss(**kwargs)
    elif loss_type.lower() == 'adaptive':
        return AdaptiveHydroLoss(**kwargs)
    elif loss_type.lower() == 'enhanced':
        return EnhancedCombinedLoss(**kwargs)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æŸå¤±å‡½æ•°ç±»å‹: {loss_type}")
