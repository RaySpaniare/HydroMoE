# -*- coding: utf-8 -*-
"""
MoE_pbm.py
ä¼˜åŒ–åçš„PBMæ¨¡å—ï¼šæ”¯æŒé¢„è®¡ç®—ç»“æœåŠ è½½å’ŒCMA-ESå‚æ•°
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, Any, Optional, Tuple
from MoE_cmaes_loader import CMAESParamLoader


class OptimizedPBM(nn.Module):
    """ä¼˜åŒ–åçš„ç‰©ç†æœºç†æ¨¡å‹"""
    
    def __init__(self, config: Dict[str, Any], cmaes_loader: CMAESParamLoader = None):
        """
        åˆå§‹åŒ–ä¼˜åŒ–åçš„PBMæ¨¡å—
        
        Args:
            config: é…ç½®å­—å…¸
            cmaes_loader: CMA-ESå‚æ•°åŠ è½½å™¨
        """
        super().__init__()
        self.config = config
        self.cmaes_loader = cmaes_loader or CMAESParamLoader()
        self.use_precomputed = config.get('use_precomputed_pbm', False)  # é»˜è®¤å…³é—­é¢„è®¡ç®—
        
        # åˆå§‹åŒ–é»˜è®¤å‚æ•°
        self.default_params = self._get_default_params()
        
    def _get_default_params(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤å‚æ•°"""
        return {
            'snow_params': {
                'snowf_upper': 3.3,
                'rainf_lower': -1.1,
                'melt_crit': 0.0,
                'frc_liquid': 0.06,
                'melt_factor': 3.0,
                'melt_temp': 0.0
            },
            'runoff_params': {
                'beta_e': 0.75,
                'wmin_ratio': 0.1,
                'wmax_ratio': 1.0,
                'c_max': 100.0,
                'b': 0.5,
                'k': 0.1,
                'alpha': 0.5
            },
            'drainage_params': {
                'qsb_min': 1.15741e-05,
                'qsb_max': 1.15741e-04,
                'qsb_low': 0.9,
                'qsb_hig': 0.9,
                'qsb_exp': 1.5,
                'gw_recharge': 0.2
            },
            'et_params': {
                'rm_crit': 0.7,
                'wilting_ratio': 0.1,
                'sevap_low': 0.1,
                'et_alpha': 1.0,
                'transp_fraction': 1.0,
                'et_beta': 1.0
            },
            'groundwater_params': {
                'retention_time': 30.0,
                'baseflow_threshold': 0.3,
                'k_drainage': 0.05,
                'drainage_exp': 1.5,
                'baseflow_factor': 0.3,
                'groundwater_decay': 0.95
            }
        }
    
    def get_station_params(self, station_id: str) -> Dict[str, Any]:
        """è·å–ç«™ç‚¹ç‰¹å®šå‚æ•°"""
        if self.cmaes_loader:
            return self.cmaes_loader.get_station_params(station_id)
        return self.default_params
    
    def forward(self, inputs: Dict[str, torch.Tensor], station_ids: torch.Tensor, station_ids_str: list = None) -> Dict[str, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        
        Args:
            inputs: è¾“å…¥æ•°æ®å­—å…¸
            station_ids: ç«™ç‚¹IDå¼ é‡
            
        Returns:
            è¾“å‡ºç»“æœå­—å…¸
        """
        batch_size = inputs['precip'].shape[0]
        device = inputs['precip'].device
        
        # åˆå§‹åŒ–è¾“å‡º
        outputs = {
            'snow_output': torch.zeros(batch_size, device=device),
            'runoff_output': torch.zeros(batch_size, device=device),
            'et_output': torch.zeros(batch_size, device=device),
            'groundwater_output': torch.zeros(batch_size, device=device)
        }
        
        # å¦‚æœä½¿ç”¨é¢„è®¡ç®—ç»“æœï¼Œç›´æ¥åŠ è½½
        if self.use_precomputed:
            for i in range(batch_size):
                station_id = f"camels_{station_ids[i].item():08d}"
                time_step = inputs.get('time_step', torch.tensor(0, device=device))[i].item()
                
                pbm_results = self.cmaes_loader.get_pbm_results(station_id, time_step)
                if pbm_results:
                    for key, value in pbm_results.items():
                        if key in outputs:
                            outputs[key][i] = value
                else:
                    # å¦‚æœé¢„è®¡ç®—ç»“æœä¸å¯ç”¨ï¼Œä½¿ç”¨å®æ—¶è®¡ç®—
                    outputs = self._compute_realtime_pbm(inputs, station_ids, i, outputs)
        else:
            # ä½¿ç”¨å®æ—¶è®¡ç®—
            outputs = self._compute_realtime_pbm(inputs, station_ids, 0, outputs, station_ids_str)
        
        return outputs
    
    def _compute_realtime_pbm(self, inputs: Dict[str, torch.Tensor], 
                            station_ids: torch.Tensor, 
                            batch_idx: int, 
                            outputs: Dict[str, torch.Tensor],
                            station_ids_str: list = None) -> Dict[str, torch.Tensor]:
        """å®æ—¶è®¡ç®—PBMï¼ˆæ‰¹é‡ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        batch_size = inputs['precip'].shape[0]
        device = inputs['precip'].device
        
        # ğŸš€ ä¼˜åŒ–ï¼šæ‰¹é‡æå–é©±åŠ¨æ•°æ®ï¼Œé¿å…é€ä¸ªitem()è°ƒç”¨
        precip_batch = inputs['precip']  # [batch_size]
        temp_batch = inputs['temp']      # [batch_size]
        pet_batch = inputs['pet']        # [batch_size]
        
        # ğŸš€ ä¼˜åŒ–ï¼šæ‰¹é‡è·å–å‚æ•°ï¼ˆä½¿ç”¨é»˜è®¤å‚æ•°ä½œä¸ºåŸºå‡†ï¼Œé¿å…é€ä¸ªæŸ¥è¯¢ï¼‰
        # å¯¹äºå¤§å¤šæ•°ç«™ç‚¹ä½¿ç”¨é»˜è®¤å‚æ•°ï¼Œç‰¹æ®Šç«™ç‚¹å¯ä»¥é€ä¸ªè¦†ç›–
        snow_melt_factor = 3.0
        c_max = 100.0
        beta_e = 2.0
        et_alpha = 1.0
        transp_fraction = 0.5
        k_drainage = 0.05
        baseflow_factor = 0.3
        
        # ğŸš€ æ‰¹é‡è®¡ç®—é›ªæ°´è¿‡ç¨‹
        snowf_upper = 3.3
        rainf_lower = -1.1
        temp_range = snowf_upper - rainf_lower
        snow_fraction = torch.clamp((snowf_upper - temp_batch) / temp_range, 0, 1)
        snowf = precip_batch * snow_fraction
        rainf = F.softplus(precip_batch - snowf - 1e-6)
        
        # æ‰¹é‡èé›ªè®¡ç®—
        temp_diff = temp_batch - 0.0  # melt_temp = 0
        smelt_pot = torch.where(temp_diff > 0, snow_melt_factor * temp_diff, torch.zeros_like(temp_batch))
        smelt_pot = F.softplus(smelt_pot)
        
        snow_output = snowf * snow_melt_factor + smelt_pot
        
        #  æ‰¹é‡å¾„æµè®¡ç®—
        effective_precip = rainf + smelt_pot
        runoff_output = effective_precip * (1.0 - torch.exp(-effective_precip / (c_max * beta_e)))
        
        #  æ‰¹é‡ETè®¡ç®—
        et_output = pet_batch * et_alpha * transp_fraction
        
        #  æ‰¹é‡åœ°ä¸‹æ°´è®¡ç®—
        groundwater_output = effective_precip * k_drainage + et_output * baseflow_factor
        
        # ç¡®ä¿éè´Ÿè¾“å‡ºï¼ˆæ‰¹é‡æ“ä½œï¼‰
        outputs['snow_output'] = torch.clamp(snow_output, min=0.0)
        outputs['runoff_output'] = torch.clamp(runoff_output, min=0.0)
        outputs['et_output'] = torch.clamp(et_output, min=0.0)
        outputs['groundwater_output'] = torch.clamp(groundwater_output, min=0.0)
        
        return outputs
    
    def get_snow_process(self, precip: torch.Tensor, temp: torch.Tensor, 
                        station_id: str, params: Dict[str, Any]) -> Tuple[torch.Tensor, torch.Tensor]:
        """é›ªæ°´è¿‡ç¨‹è®¡ç®—"""
        # ä½¿ç”¨ç«™ç‚¹ç‰¹å®šå‚æ•°
        snow_params = params.get('snow_params', self.default_params['snow_params'])
        
        # é™é›¨é™é›ªåˆ†ç¦»
        snowf, rainf = self._get_rain_and_snow(precip, temp, snow_params)
        
        # èé›ªè®¡ç®—
        smelt_pot = self._get_potential_snowmelt(temp, snow_params)
        
        return snowf, rainf
    
    def _get_rain_and_snow(self, precip: torch.Tensor, temp: torch.Tensor, 
                          snow_params: Dict[str, Any]) -> Tuple[torch.Tensor, torch.Tensor]:
        """é™é›¨é™é›ªåˆ†ç¦»"""
        snowf_upper = snow_params['snowf_upper']
        rainf_lower = snow_params['rainf_lower']
        
        temp_range = snowf_upper - rainf_lower
        if temp_range > 1e-8:
            snow_fraction = torch.clamp((snowf_upper - temp) / temp_range, 0, 1)
        else:
            snow_fraction = torch.where(temp <= snowf_upper, 
                                      torch.ones_like(temp), 
                                      torch.zeros_like(temp))
        
        snowf = precip * snow_fraction
        rainf = F.softplus(precip - snowf - 1e-6)
        
        return snowf, rainf
    
    def _get_potential_snowmelt(self, temp: torch.Tensor, 
                               snow_params: Dict[str, Any]) -> torch.Tensor:
        """æ½œåœ¨èé›ªè®¡ç®—"""
        melt_temp = snow_params['melt_temp']
        melt_factor = snow_params['melt_factor']
        
        temp_diff = temp - melt_temp
        smelt_pot = torch.where(temp_diff > 0, 
                               melt_factor * temp_diff, 
                               torch.zeros_like(temp))
        
        return F.softplus(smelt_pot)
    
    def get_runoff_process(self, throughfall: torch.Tensor, rootmoist: torch.Tensor,
                          station_id: str, params: Dict[str, Any]) -> Tuple[torch.Tensor, torch.Tensor]:
        """å¾„æµç”Ÿæˆè¿‡ç¨‹"""
        runoff_params = params.get('runoff_params', self.default_params['runoff_params'])
        
        # åœ°è¡¨å¾„æµè®¡ç®—
        qs = self._get_surface_runoff(throughfall, rootmoist, runoff_params)
        
        # åœ°ä¸‹å¾„æµè®¡ç®—
        qsb = self._get_drainage(rootmoist, runoff_params)
        
        return qs, qsb
    
    def _get_surface_runoff(self, throughfall: torch.Tensor, rootmoist: torch.Tensor,
                           runoff_params: Dict[str, Any]) -> torch.Tensor:
        """åœ°è¡¨å¾„æµè®¡ç®—"""
        beta = runoff_params['beta_e']
        c_max = runoff_params['c_max']
        b = runoff_params['b']
        
        wmin = c_max * runoff_params.get('wmin_ratio', 0.1)
        wmax = c_max * runoff_params.get('wmax_ratio', 1.0)
        
        # ç®€åŒ–çš„åœ°è¡¨å¾„æµè®¡ç®—
        if c_max > wmin and rootmoist > wmin:
            rm_sub = wmax - (wmax - wmin) * (1 - (rootmoist - wmin) / (c_max - wmin))**(1 / (1 + beta))
            rm_sub = torch.max(rootmoist, rm_sub)
        else:
            rm_sub = rootmoist
        
        # è®¡ç®—å¾„æµ
        if wmax > wmin:
            c1 = torch.clamp(((wmax - rm_sub) / (wmax - wmin))**(1 + beta), 0, 1)
            if rm_sub + throughfall <= wmax:
                c2 = torch.clamp(((wmax - rm_sub - throughfall) / (wmax - wmin))**(1 + beta), 0, 1)
            else:
                c2 = torch.zeros_like(c1)
        else:
            c1 = c2 = torch.zeros_like(throughfall)
        
        qs = throughfall - torch.max(0, wmin - rootmoist) - ((wmax - wmin) / (1 + beta)) * (c1 - c2)
        
        return F.softplus(qs)
    
    def _get_drainage(self, rootmoist: torch.Tensor, runoff_params: Dict[str, Any]) -> torch.Tensor:
        """åœ°ä¸‹å¾„æµè®¡ç®—"""
        c_max = runoff_params['c_max']
        qsb_min = 1.15741e-05
        qsb_max = 1.15741e-04
        qsb_low = 0.9
        qsb_hig = 0.9
        qsb_exp = 1.5
        
        if c_max <= 1e-10:
            return torch.zeros_like(rootmoist)
        
        no_qsb = (c_max <= 1e-10) | (rootmoist <= c_max * qsb_low)
        full_qsb = (c_max > 1e-10) & (rootmoist >= c_max * qsb_hig)
        
        qsb = torch.where(no_qsb, 
                         torch.zeros_like(rootmoist),
                         qsb_min * (rootmoist / c_max))
        
        if full_qsb.any():
            max_qsb = qsb + (qsb_max - qsb_min) * \
                     ((rootmoist - c_max * qsb_hig) / (c_max - c_max * qsb_hig))**qsb_exp
            qsb = torch.where(full_qsb, max_qsb, qsb)
        
        qsb = torch.min(qsb, rootmoist)
        
        return F.softplus(qsb)
    
    def get_et_process(self, potevap: torch.Tensor, rootmoist: torch.Tensor,
                      station_id: str, params: Dict[str, Any]) -> Tuple[torch.Tensor, torch.Tensor]:
        """è’¸æ•£å‘è¿‡ç¨‹"""
        et_params = params.get('et_params', self.default_params['et_params'])
        
        # æ¤ç‰©è’¸è…¾
        transp = self._get_transpiration(potevap, rootmoist, et_params)
        
        # åœŸå£¤è’¸å‘
        sevap = self._get_soilevap(potevap, rootmoist, et_params)
        
        return transp, sevap
    
    def _get_transpiration(self, potevap: torch.Tensor, rootmoist: torch.Tensor,
                          et_params: Dict[str, Any]) -> torch.Tensor:
        """æ¤ç‰©è’¸è…¾è®¡ç®—"""
        rm_crit = et_params['rm_crit']
        wilting_ratio = et_params.get('wilting_ratio', 0.1)
        transp_frac = et_params['transp_fraction']
        et_alpha = et_params['et_alpha']
        
        # ç®€åŒ–çš„è’¸è…¾è®¡ç®—
        transp_stress = torch.clamp((rootmoist - wilting_ratio) / (rm_crit - wilting_ratio), 0, 1)
        transp = potevap * transp_stress * transp_frac * et_alpha
        
        return F.softplus(transp)
    
    def _get_soilevap(self, potevap: torch.Tensor, rootmoist: torch.Tensor,
                     et_params: Dict[str, Any]) -> torch.Tensor:
        """åœŸå£¤è’¸å‘è®¡ç®—"""
        sevap_low = et_params.get('sevap_low', 0.1)
        et_alpha = et_params['et_alpha']
        
        # ç®€åŒ–çš„åœŸå£¤è’¸å‘è®¡ç®—
        sevap_stress = torch.clamp((rootmoist - sevap_low) / (1 - sevap_low), 0, 1)
        sevap = potevap * sevap_stress * et_alpha
        
        return F.softplus(sevap)
    
    def get_groundwater_process(self, groundwstor_old: torch.Tensor, qsb: torch.Tensor,
                               station_id: str, params: Dict[str, Any]) -> Tuple[torch.Tensor, torch.Tensor]:
        """åœ°ä¸‹æ°´è¿‡ç¨‹"""
        gw_params = params.get('groundwater_params', self.default_params['groundwater_params'])
        
        retention_time = gw_params['retention_time']
        baseflow_thresh = gw_params['baseflow_threshold']
        gw_recharge = gw_params.get('gw_recharge', 0.2)
        
        # åŸºæµè®¡ç®—
        qg = torch.where(groundwstor_old > baseflow_thresh,
                        groundwstor_old / retention_time,
                        torch.zeros_like(groundwstor_old))
        
        # åœ°ä¸‹æ°´æ›´æ–°
        effective_qsb = qsb * gw_recharge
        groundwstor_new = groundwstor_old + effective_qsb - qg
        
        return F.softplus(groundwstor_new), F.softplus(qg)


def test_optimized_pbm():
    """æµ‹è¯•ä¼˜åŒ–åçš„PBMæ¨¡å—"""
    print("ğŸ§ª æµ‹è¯•ä¼˜åŒ–åçš„PBMæ¨¡å—...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 4
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    inputs = {
        'precip': torch.randn(batch_size, device=device),
        'temp': torch.randn(batch_size, device=device),
        'pet': torch.randn(batch_size, device=device),
        'time_step': torch.arange(batch_size, device=device)
    }
    
    station_ids = torch.tensor([9378630, 9378640, 9378650, 9378660], device=device)
    
    # åˆ›å»ºä¼˜åŒ–åçš„PBMæ¨¡å—
    config = {'use_precomputed_pbm': True}
    pbm = OptimizedPBM(config)
    
    # å‰å‘ä¼ æ’­
    outputs = pbm(inputs, station_ids)
    
    print(f"ğŸ“Š è¾“å‡ºå½¢çŠ¶:")
    for key, value in outputs.items():
        print(f"  {key}: {value.shape}")
    
    print("âœ… ä¼˜åŒ–åçš„PBMæ¨¡å—æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    test_optimized_pbm()
