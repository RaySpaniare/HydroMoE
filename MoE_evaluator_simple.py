"""
ç®€åŒ–è¯„ä¼°æ¨¡å— - åŒ…å«æ¨¡å‹è¯„ä¼°ç›¸å…³åŠŸèƒ½
"""

import torch
import numpy as np
import logging
from datetime import datetime
import os
import glob
import pandas as pd

from MoE_metrics import compute_all_metrics

logger = logging.getLogger(__name__)


def evaluate_enhanced_model(model, test_loader, device, output_prefix: str = 'enhanced_real_runoff_predictions'):
    """è¯„ä¼°å¢å¼ºæ¨¡å‹ï¼š
    - æ”¶é›†é¢„æµ‹ä¸ç›®æ ‡
    - åå½’ä¸€åŒ–åˆ°çœŸå®å•ä½ï¼ˆè‹¥å¯ç”¨ï¼‰
    - ä¿å­˜æ—¶é—´åºåˆ— CSV ä¸ç«™ç‚¹è¯„ä¼° CSV
    - æ‰“å°æ€»ä½“æŒ‡æ ‡
    """
    print("\nğŸ“Š è¯„ä¼°å¢å¼ºæ¨¡å‹...")

    model.eval()
    preds_list, targets_list = [], []
    station_names, lons, lats, dates = [], [], [], []
    # ä¸ºé€æ—¥é‡å»ºå‡†å¤‡ï¼šæ”¶é›†æ¯æ¡æ ·æœ¬çš„ç«™ç‚¹ä¸æ—¥æœŸèŒƒå›´
    records = []  # æ¯æ¡è®°å½•åŒ…å«: station_id, start_date, end_date, pred, target, lon, lat

    # ç«™ç‚¹é—¨æ§ä½¿ç”¨ç‡èšåˆå™¨
    gate_usage = {}

    with torch.no_grad():
        for batch in test_loader:
            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}
            outputs = model(batch, return_gate_info=True)
            predictions = outputs['runoff']

            # ğŸš€ ä¼˜åŒ–ï¼šå‡å°‘reshapeæ“ä½œï¼Œç›´æ¥flatten
            preds_np = predictions.cpu().numpy().flatten()
            targs_np = batch['targets'].cpu().numpy().flatten()
            preds_list.append(preds_np)
            targets_list.append(targs_np)

            if 'station_id' in batch:
                station_names.extend(batch['station_id'])
            if 'lon' in batch:
                try:
                    lons.extend(batch['lon'].cpu().numpy().reshape(-1).tolist())
                except Exception:
                    pass
            if 'lat' in batch:
                try:
                    lats.extend(batch['lat'].cpu().numpy().reshape(-1).tolist())
                except Exception:
                    pass
            # è®°å½•çª—å£è¦†ç›–ä¿¡æ¯ï¼ˆé€æ—¥é‡å»ºç”¨ï¼‰+ æ”¶é›†æ—¥æœŸä¿¡æ¯åˆ°datesåˆ—è¡¨
            try:
                sid_list = batch.get('station_id', [])
                sd_list = batch.get('start_date', [])
                ed_list = batch.get('end_date', [])
                for i in range(len(preds_np)):
                    sid = sid_list[i] if i < len(sid_list) else None
                    sd = sd_list[i] if i < len(sd_list) else None
                    ed = ed_list[i] if i < len(ed_list) else None
                    
                    # ğŸ”¥ ä¿®å¤ï¼šå°†end_dateæ·»åŠ åˆ°datesåˆ—è¡¨ä¸­ï¼ˆé¢„æµ‹å¯¹åº”çš„æ—¥æœŸï¼‰
                    if ed is not None:
                        dates.append(ed)
                    elif sd is not None:
                        dates.append(sd)
                    else:
                        dates.append(None)
                    
                    lon_i = None
                    lat_i = None
                    try:
                        if 'lon' in batch:
                            lon_i = float(batch['lon'][i].item()) if hasattr(batch['lon'][i], 'item') else float(batch['lon'][i])
                        if 'lat' in batch:
                            lat_i = float(batch['lat'][i].item()) if hasattr(batch['lat'][i], 'item') else float(batch['lat'][i])
                    except Exception:
                        pass
                    records.append({
                        'station_id': sid,
                        'start_date': sd,
                        'end_date': ed,
                        'pred': float(preds_np[i]),
                        'target': float(targs_np[i]),
                        'lon': lon_i,
                        'lat': lat_i,
                    })
            except Exception:
                pass

            # æ”¶é›†é—¨æ§ä½¿ç”¨ç‡ï¼ˆPBM vs NNï¼‰ä¸Regimeæƒé‡
            try:
                sid_list = batch['station_id'] if 'station_id' in batch else None
                if sid_list is not None and 'gate_info' in outputs:
                    module_gates = outputs['gate_info'].get('module_gates', {})
                    regime_w = outputs.get('regime_weights', None)
                    bsz = predictions.shape[0]
                    for i in range(bsz):
                        sid = sid_list[i]
                        rec = gate_usage.setdefault(sid, {
                            'count': 0,
                            'snow_pbm': 0.0, 'snow_nn': 0.0,
                            'runoff_pbm': 0.0, 'runoff_nn': 0.0,
                            'et_pbm': 0.0, 'et_nn': 0.0,
                            'drainage_pbm': 0.0, 'drainage_nn': 0.0,
                            'regime_low': 0.0, 'regime_mid': 0.0, 'regime_high': 0.0,
                        })
                        rec['count'] += 1
                        for mname in ['snow', 'runoff', 'et', 'drainage']:
                            if mname in module_gates and 'effective_gate' in module_gates[mname]:
                                gw = module_gates[mname]['effective_gate']  # [B,2]
                                pbm_w = float(gw[i, 0].detach().cpu().item())
                                nn_w = float(gw[i, 1].detach().cpu().item())
                                rec[f'{mname}_pbm'] += pbm_w
                                rec[f'{mname}_nn'] += nn_w
                        if regime_w is not None:
                            rw = regime_w  # [B,3]
                            rec['regime_low'] += float(rw[i, 0].detach().cpu().item())
                            rec['regime_mid'] += float(rw[i, 1].detach().cpu().item())
                            rec['regime_high'] += float(rw[i, 2].detach().cpu().item())
            except Exception:
                pass

    if not preds_list:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æµ‹è¯•æ•°æ®")
        return {'R2': 0.0, 'KGE': 0.0, 'RMSE': float('inf')}

    predictions = np.concatenate(preds_list, axis=0)
    targets = np.concatenate(targets_list, axis=0)

    # åå½’ä¸€åŒ–ï¼ˆè‹¥å¯ç”¨ï¼‰
    ds = getattr(test_loader, 'dataset', None)
    target_scaler = getattr(ds, 'scalers', {}).get('target_scaler') if getattr(ds, 'scalers', None) else None
    if target_scaler is not None:
        try:
            predictions = target_scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()
            targets = target_scaler.inverse_transform(targets.reshape(-1, 1)).flatten()
            predictions = np.clip(predictions, a_min=0.0, a_max=None)
        except Exception:
            pass

    # æŒ‡æ ‡
    metrics = compute_all_metrics(targets, predictions)

    print("ğŸ¯ æœ€ç»ˆæµ‹è¯•ç»“æœ:")
    print(f"  RÂ²: {metrics.get('R2', 0):.4f}")
    print(f"  KGE: {metrics.get('KGE', 0):.4f}")
    print(f"  RMSE: {metrics.get('RMSE', 0):.4f}")
    print(f"  Bias: {metrics.get('bias', 0):.4f}")

    # ä¿å­˜CSVï¼ˆåŸå§‹æ‹¼æ¥ï¼‰
    out_dir = os.path.join('outputs', output_prefix)
    os.makedirs(out_dir, exist_ok=True)

    df = pd.DataFrame({
        'predicted_runoff': predictions,
        'actual_runoff': targets,
    })
    if station_names:
        df['station_id'] = station_names[:len(df)]
    if lons:
        df['lon'] = (lons[:len(df)] if len(lons) >= len(df) else lons + [None]*(len(df)-len(lons)))
    if lats:
        df['lat'] = (lats[:len(df)] if len(lats) >= len(df) else lats + [None]*(len(df)-len(lats)))
    if dates:
        try:
            df['date'] = pd.to_datetime(dates[:len(df)])
        except Exception:
            df['date'] = dates[:len(df)]

    # ğŸ”¥ ç°åœ¨æµ‹è¯•é›†ä½¿ç”¨stride=1ï¼Œå·²ç»åŒ…å«é€æ—¥é¢„æµ‹ï¼Œåªéœ€è¡¥å……ç»çº¬åº¦ä¿¡æ¯
    if 'station_id' in df.columns:
        try:
            # æ˜ å°„lon/latï¼ˆæ¯ç«™å›ºå®šå€¼ï¼‰
            if 'lon' in df.columns:
                lon_map = df[['station_id', 'lon']].dropna().drop_duplicates(subset=['station_id']).set_index('station_id')['lon'].to_dict()
                df['lon'] = df['station_id'].map(lon_map).fillna(df['lon'])
            if 'lat' in df.columns:
                lat_map = df[['station_id', 'lat']].dropna().drop_duplicates(subset=['station_id']).set_index('station_id')['lat'].to_dict()
                df['lat'] = df['station_id'].map(lat_map).fillna(df['lat'])
        except Exception:
            pass
    
    # ğŸ”¥ ä¿®å¤ï¼šåªä¿ç•™çœŸæ­£çš„æµ‹è¯•æœŸé¢„æµ‹ï¼ˆä»test_startå¼€å§‹ï¼‰
    ds_cfg = getattr(getattr(test_loader, 'dataset', None), 'config', None)
    if ds_cfg is not None and 'date' in df.columns:
        try:
            test_start = pd.to_datetime(ds_cfg.test_start)
            test_end = pd.to_datetime(ds_cfg.test_end)
            
            # ç­›é€‰çœŸæ­£çš„æµ‹è¯•æœŸæ•°æ®
            test_mask = (df['date'] >= test_start) & (df['date'] <= test_end)
            df_before_filter = df.copy()
            df = df[test_mask].copy()
            
            print(f"ğŸ“Š ç­›é€‰æµ‹è¯•æœŸé¢„æµ‹å®Œæˆ:")
            print(f"   - æ‰©å±•æ•°æ®ç‚¹: {len(df_before_filter)}")
            print(f"   - æµ‹è¯•æœŸæ•°æ®ç‚¹: {len(df)} (ä» {test_start.date()} åˆ° {test_end.date()})")
            print(f"   - æœ‰æ•ˆé¢„æµ‹ç‚¹: {df['predicted_runoff'].notna().sum()}")
            print(f"   - è¦†ç›–ç‡: {df['predicted_runoff'].notna().sum()/len(df)*100:.1f}%")
        except Exception as e:
            print(f"   âš ï¸ æµ‹è¯•æœŸç­›é€‰å¤±è´¥: {e}")
            print(f"ğŸ“Š ç”Ÿæˆé€æ—¥é¢„æµ‹å®Œæˆ:")
            print(f"   - æ€»æ•°æ®ç‚¹: {len(df)}")
            print(f"   - æœ‰æ•ˆé¢„æµ‹ç‚¹: {df['predicted_runoff'].notna().sum()}")
            print(f"   - è¦†ç›–ç‡: {df['predicted_runoff'].notna().sum()/len(df)*100:.1f}%")
    else:
        print(f"ğŸ“Š ç”Ÿæˆé€æ—¥é¢„æµ‹å®Œæˆ:")
        print(f"   - æ€»æ•°æ®ç‚¹: {len(df)}")
        print(f"   - æœ‰æ•ˆé¢„æµ‹ç‚¹: {df['predicted_runoff'].notna().sum()}")
        print(f"   - è¦†ç›–ç‡: {df['predicted_runoff'].notna().sum()/len(df)*100:.1f}%")

    # è¯¯å·®åˆ—åœ¨è¡¥é½åå†è®¡ç®—ï¼ˆä¿ç•™NaNä½ç½®ï¼‰
    df['error'] = df['predicted_runoff'] - df['actual_runoff']

    # ç›¸å¯¹è¯¯å·®ï¼ˆé¿å…é™¤ 0ï¼‰
    df['relative_error_percent'] = ((df['error']) / (df['actual_runoff'] + 1e-8)) * 100

    csv_path = os.path.join(out_dir, 'real_runoff_predictions.csv')
    df.to_csv(csv_path, index=False)
    print(f"  ğŸ’¾ æ—¶é—´åºåˆ—CSVå·²ä¿å­˜: {csv_path}")

    # é¢å¤–å¯¼å‡ºï¼šé€ç«™ç‚¹é€æ—¥æœŸå¯¹é½çš„å»é‡ç‰ˆæœ¬ï¼ˆæ¯ç«™ä¸€å¤©ä¸€è¡Œï¼Œé¢„æµ‹ä¸çœŸå®å‡æœ‰æ•ˆï¼‰
    try:
        if 'station_id' in df.columns and 'date' in df.columns:
            df_aligned = df[['station_id','date','lon','lat','actual_runoff','predicted_runoff']].copy()
            # ä¸¢å¼ƒæ— æ•ˆå¯¹
            df_aligned = df_aligned[np.isfinite(df_aligned['actual_runoff']) & np.isfinite(df_aligned['predicted_runoff'])]
            # å¯èƒ½å­˜åœ¨åŒä¸€ç«™ç‚¹-æ—¥æœŸå¤šæ¡è®°å½•ï¼ˆçª—å£é‡å ï¼‰ï¼Œå–å‡å€¼å¹¶ä¿ç•™é¦–ä¸ªç»çº¬åº¦
            agg = {
                'actual_runoff': 'mean',
                'predicted_runoff': 'mean',
                'lon': 'first',
                'lat': 'first',
            }
            df_aligned = df_aligned.groupby(['station_id','date'], as_index=False).agg(agg)
            aligned_path = os.path.join(out_dir, 'real_runoff_predictions_aligned.csv')
            df_aligned.to_csv(aligned_path, index=False)
            print(f"  ğŸ’¾ å¯¹é½CSVå·²ä¿å­˜: {aligned_path}")
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆå¯¹é½CSVå¤±è´¥: {e}")


    # ç«™ç‚¹è¯„ä¼°
    if 'station_id' in df.columns:
        station_stats = []
        for sid, g in df.groupby('station_id'):
            y_true = g['actual_runoff'].to_numpy()
            y_pred = g['predicted_runoff'].to_numpy()
            mask = np.isfinite(y_true) & np.isfinite(y_pred)
            valid_count = int(mask.sum())
            m = compute_all_metrics(y_true[mask], y_pred[mask]) if valid_count > 0 else {'R2': np.nan, 'KGE': np.nan, 'RMSE': np.nan, 'bias': np.nan}
            lon_val = float(g['lon'].iloc[0]) if 'lon' in g.columns and len(g['lon'])>0 and pd.notna(g['lon'].iloc[0]) else np.nan
            lat_val = float(g['lat'].iloc[0]) if 'lat' in g.columns and len(g['lat'])>0 and pd.notna(g['lat'].iloc[0]) else np.nan
            station_stats.append({
                'station_id': sid,
                'lon': lon_val,
                'lat': lat_val,
                'days_total': int(len(g)),
                'sample_count': valid_count,
                'mean_actual_runoff': float(np.nanmean(g['actual_runoff'])),
                'mean_predicted_runoff': float(np.nanmean(g['predicted_runoff'])),
                'rmse': float(np.sqrt(np.nanmean((g['error'])**2))),
                'R2': m.get('R2', np.nan),
                'KGE': m.get('KGE', np.nan),
            })
        stats_df = pd.DataFrame(station_stats)
        stats_path = os.path.join(out_dir, 'station_performance_real_runoff.csv')
        stats_df.to_csv(stats_path, index=False)
        print(f"  ğŸ’¾ ç«™ç‚¹è¯„ä¼°CSVå·²ä¿å­˜: {stats_path}")

        # ç®€è¦æ¦‚è§ˆ
        if len(stats_df) > 0 and 'R2' in stats_df.columns and stats_df['R2'].notna().any():
            best_row = stats_df.loc[stats_df['R2'].idxmax()]
            worst_row = stats_df.loc[stats_df['R2'].idxmin()]
            print(f"  ğŸ† æœ€ä½³ç«™ç‚¹: {best_row['station_id']} (RÂ²={best_row['R2']:.3f})")
            print(f"  ğŸ¯ å¾…æå‡ç«™: {worst_row['station_id']} (RÂ²={worst_row['R2']:.3f})")

        # ç«™ç‚¹å±‚é¢æ±‡æ€»ç»Ÿè®¡ï¼ˆå‡å€¼/ä¸­ä½æ•°ï¼‰
        try:
            r2_vals = stats_df['R2'].dropna()
            kge_vals = stats_df['KGE'].dropna()
            if len(r2_vals) > 0:
                r2_mean = float(r2_vals.mean())
                r2_median = float(r2_vals.median())
                print(f"  ğŸ“¦ ç«™ç‚¹RÂ²: å‡å€¼={r2_mean:.4f}, ä¸­ä½æ•°={r2_median:.4f}")
            if len(kge_vals) > 0:
                kge_mean = float(kge_vals.mean())
                kge_median = float(kge_vals.median())
                print(f"  ğŸ“¦ ç«™ç‚¹KGE: å‡å€¼={kge_mean:.4f}, ä¸­ä½æ•°={kge_median:.4f}")

            # ä¿å­˜æ±‡æ€»JSON
            import json
            summary = {
                'station_count': int(len(stats_df)),
                'R2': {
                    'mean': float(r2_vals.mean()) if len(r2_vals)>0 else None,
                    'median': float(r2_vals.median()) if len(r2_vals)>0 else None,
                    'p25': float(r2_vals.quantile(0.25)) if len(r2_vals)>0 else None,
                    'p10': float(r2_vals.quantile(0.10)) if len(r2_vals)>0 else None,
                    'min': float(r2_vals.min()) if len(r2_vals)>0 else None,
                    'max': float(r2_vals.max()) if len(r2_vals)>0 else None,
                },
                'KGE': {
                    'mean': float(kge_vals.mean()) if len(kge_vals)>0 else None,
                    'median': float(kge_vals.median()) if len(kge_vals)>0 else None,
                    'p25': float(kge_vals.quantile(0.25)) if len(kge_vals)>0 else None,
                    'p10': float(kge_vals.quantile(0.10)) if len(kge_vals)>0 else None,
                    'min': float(kge_vals.min()) if len(kge_vals)>0 else None,
                    'max': float(kge_vals.max()) if len(kge_vals)>0 else None,
                },
            }
            summary_path = os.path.join(out_dir, 'station_metrics_summary.json')
            with open(summary_path, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            print(f"  ğŸ’¾ ç«™ç‚¹æŒ‡æ ‡æ±‡æ€»å·²ä¿å­˜: {summary_path}")

            # å¯¼å‡ºä½RÂ²ç«™ç‚¹åˆ—è¡¨ï¼ˆTop-Næˆ–åº•éƒ¨10%ï¼‰
            if len(stats_df) > 0 and 'R2' in stats_df.columns:
                n = max(5, min(10, len(stats_df)))
                low_df = stats_df.sort_values('R2', ascending=True).head(n)
                low_cols = [c for c in ['station_id','lon','lat','R2','KGE','rmse','mean_actual_runoff','mean_predicted_runoff','sample_count'] if c in low_df.columns]
                low_path = os.path.join(out_dir, 'low_r2_stations.csv')
                low_df[low_cols].to_csv(low_path, index=False)
                names = ", ".join([f"{row.station_id}(RÂ²={row.R2:.3f})" for _, row in low_df.iterrows()])
                print(f"  ğŸ“‰ ä½RÂ²ç«™ç‚¹Top{len(low_df)}: {names}")
                print(f"  ğŸ’¾ å·²å¯¼å‡ºä½RÂ²ç«™ç‚¹åˆ—è¡¨: {low_path}")
        except Exception as e:
            print(f"âš ï¸ ç«™ç‚¹å±‚é¢ç»Ÿè®¡å¤±è´¥: {e}")

        # å¯¼å‡ºé—¨æ§ä½¿ç”¨ç‡ï¼ˆå¦‚å·²æ”¶é›†ï¼‰
        try:
            if gate_usage:
                usage_rows = []
                for sid, rec in gate_usage.items():
                    c = rec.pop('count', 1)
                    row = {'station_id': sid}
                    for k, v in rec.items():
                        row[k] = v / max(1, c)
                    usage_rows.append(row)
                usage_df = pd.DataFrame(usage_rows)
                # å°½é‡è¡¥å……ç»çº¬åº¦
                if 'station_id' in stats_df.columns:
                    usage_df = usage_df.merge(stats_df[['station_id','lon','lat']], on='station_id', how='left')
                # å›ºå®šåˆ—é¡ºåº
                ordered_cols = [
                    'station_id','lon','lat',
                    'snow_pbm','snow_nn',
                    'runoff_pbm','runoff_nn',
                    'et_pbm','et_nn',
                    'drainage_pbm','drainage_nn',
                    'regime_low','regime_mid','regime_high'
                ]
                final_cols = [c for c in ordered_cols if c in usage_df.columns]
                usage_df = usage_df[final_cols]

                # ä»…ä¿ç•™ä¸€ä¸ªæ–‡ä»¶ï¼šstation_expert_weights.csv
                expert_path = os.path.join(out_dir, 'station_expert_weights.csv')
                usage_df.to_csv(expert_path, index=False)
                print(f"  ğŸ’¾ ä¸“å®¶/é—¨æ§æƒé‡CSVå·²ä¿å­˜: {expert_path}")
        except Exception as e:
            print(f"âš ï¸ å¯¼å‡ºä¸“å®¶/é—¨æ§æƒé‡å¤±è´¥: {e}")

    return metrics


def save_best_model_with_timestamp(model, base_dir="outputs", base_name="enhanced_hydromoe_best"):
    """ä¿å­˜å¸¦æ—¶é—´æˆ³çš„æœ€ä½³æ¨¡å‹"""
    os.makedirs(base_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_path = os.path.join(base_dir, f"{base_name}_{timestamp}.pth")
    torch.save(model.state_dict(), model_path)
    
    # åŒæ—¶ä¿å­˜ä¸€ä¸ªä¸å¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬ï¼ˆç”¨äºåŠ è½½ï¼‰
    simple_path = os.path.join(base_dir, f"{base_name}.pth")
    torch.save(model.state_dict(), simple_path)
    
    return model_path


def _load_state_dict_partial(model, state):
    """åç§°+å½¢çŠ¶åŒ¹é…çš„éƒ¨åˆ†åŠ è½½ï¼Œå¹¶å¯¹çº¿æ€§å±‚è¾“å…¥ç»´åº¦åšè‡ªé€‚åº”åˆå¹¶ã€‚"""
    ms = model.state_dict()
    compatible = {}
    adapted, mismatched = [], []
    for k, v in state.items():
        if k in ms:
            try:
                if ms[k].shape == v.shape:
                    compatible[k] = v
                else:
                    if len(ms[k].shape) == 2 and len(v.shape) == 2 and ms[k].shape[0] == v.shape[0]:
                        out_dim, in_model = ms[k].shape
                        _, in_ckpt = v.shape
                        merged = ms[k].clone()
                        copy_in = min(in_ckpt, in_model)
                        merged[:, :copy_in] = v[:, :copy_in]
                        compatible[k] = merged
                        adapted.append((k, (out_dim, in_ckpt), (out_dim, in_model), copy_in))
                    else:
                        mismatched.append((k, tuple(v.shape), tuple(ms[k].shape)))
            except Exception:
                mismatched.append((k, "?", "?"))
    if compatible:
        ms.update(compatible)
        model.load_state_dict(ms)
    print("ğŸ”„ ç®€åŒ–åŠ è½½å™¨ - éƒ¨åˆ†/è‡ªé€‚åº”åŠ è½½æ‘˜è¦ï¼š")
    print(f"   âœ… åŠ è½½å‚æ•°: {len(compatible)}")
    if adapted:
        for name, s_ckpt, s_model, copied in adapted[:5]:
            print(f"      - {name}: ckpt{s_ckpt} -> model{s_model}, åˆå¹¶å‰ {copied} åˆ—")
    if mismatched:
        print(f"   ğŸ§© ä»æœ‰å½¢çŠ¶ä¸åŒ¹é…(å·²å¿½ç•¥): {len(mismatched)}")
    return len(compatible) > 0


def load_best_model_if_exists(model, path="outputs/enhanced_hydromoe_best.pth"):
    """å¦‚æœå­˜åœ¨æœ€ä½³æ¨¡å‹åˆ™åŠ è½½ï¼ˆéƒ¨åˆ†åŠ è½½+è‡ªé€‚åº”ï¼Œæ”¯æŒæ—¶é—´æˆ³å›é€€ï¼‰"""
    def try_load(p):
        try:
            state = torch.load(p, map_location='cpu')
            print(f"ğŸ”„ å°è¯•åŠ è½½: {p}")
            if _load_state_dict_partial(model, state):
                print(f"âœ… åŠ è½½æœ€ä½³æ¨¡å‹: {p}")
                return True
            return False
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False

    # ğŸš€ æ·»åŠ è¯¦ç»†çš„æ–‡ä»¶æ£€æŸ¥
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹æ–‡ä»¶: {path}")
    print(f"   - æ–‡ä»¶å­˜åœ¨: {os.path.exists(path)}")
    if os.path.exists(path):
        file_size = os.path.getsize(path)
        print(f"   - æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
        
        if try_load(path):
            return True
        else:
            print(f"   âš ï¸ æ–‡ä»¶å­˜åœ¨ä½†åŠ è½½å¤±è´¥")

    # å°è¯•å¯»æ‰¾å¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶
    base_dir = os.path.dirname(path) or "."
    base_name = os.path.basename(path).replace('.pth', '')
    candidates = sorted(glob.glob(os.path.join(base_dir, f"{base_name}_*.pth")))
    
    if candidates:
        print(f"ğŸ” æ‰¾åˆ° {len(candidates)} ä¸ªå€™é€‰æ¨¡å‹æ–‡ä»¶:")
        candidates.sort(key=lambda p: os.path.getmtime(p), reverse=True)
        for i, p in enumerate(candidates[:3]):  # åªæ˜¾ç¤ºæœ€æ–°çš„3ä¸ª
            file_size = os.path.getsize(p) / 1024 / 1024
            print(f"   {i+1}. {p} ({file_size:.2f} MB)")
            
        for p in candidates:
            if try_load(p):
                return True

    print(f"âŒ æœªæ‰¾åˆ°å¯ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹: {path}")
    return False


def analyze_model_complexity(model):
    """åˆ†ææ¨¡å‹å¤æ‚åº¦"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nğŸ” æ¨¡å‹å¤æ‚åº¦åˆ†æ:")
    print(f"  æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (float32)")
    
    # åˆ†æ¨¡å—ç»Ÿè®¡
    module_params = {}
    for name, module in model.named_modules():
        if len(list(module.parameters())) > 0:
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                module_params[name] = params
    
    # æ˜¾ç¤ºä¸»è¦æ¨¡å—
    print(f"  ä¸»è¦æ¨¡å—å‚æ•°åˆ†å¸ƒ:")
    sorted_modules = sorted(module_params.items(), key=lambda x: x[1], reverse=True)
    for name, params in sorted_modules[:10]:  # æ˜¾ç¤ºå‰10ä¸ªæœ€å¤§çš„æ¨¡å—
        if params > 1000:  # åªæ˜¾ç¤ºå‚æ•°æ•°é‡å¤§äº1000çš„æ¨¡å—
            print(f"    {name}: {params:,}")
    
    return {
        'total_params': total_params,
        'trainable_params': trainable_params,
        'model_size_mb': total_params * 4 / 1024 / 1024
    }


def quick_validation_metrics(model, val_loader, device, dataset=None):
    """å¿«é€ŸéªŒè¯æŒ‡æ ‡è®¡ç®—"""
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for batch in val_loader:
            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v 
                    for k, v in batch.items()}
            
            outputs = model(batch)
            predictions = outputs['runoff']
            
            all_preds.extend(predictions.cpu().numpy())
            all_targets.extend(batch['targets'].cpu().numpy())
    
    if len(all_preds) > 0:
        return compute_all_metrics(all_targets, all_preds)
    else:
        return {'R2': 0.0, 'KGE': 0.0, 'RMSE': float('inf')}


def validate_model_simple(model, val_loader, criterion, device):
    """ç®€å•éªŒè¯æ¨¡å‹"""
    model.eval()
    val_losses = []
    
    with torch.no_grad():
        for batch in val_loader:
            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v 
                    for k, v in batch.items()}
            
            outputs = model(batch)
            predictions = outputs['runoff']
            
            # ç®€å•MSEæŸå¤±
            loss = torch.nn.functional.mse_loss(predictions, batch['targets'])
            val_losses.append(loss.item())
    
    return np.mean(val_losses) if val_losses else float('inf')


def print_training_summary(epoch, epochs, train_loss, val_loss, val_metrics, patience_counter, patience):
    """æ‰“å°è®­ç»ƒæ‘˜è¦"""
    print(f"\nğŸ“… Epoch {epoch+1}/{epochs}")
    print("-" * 50)
    print(f"  ğŸ“Š è®­ç»ƒæŸå¤±: {train_loss:.4f}")
    print(f"  ğŸ“ˆ éªŒè¯æŸå¤±: {val_loss:.4f}")
    print(f"  ğŸ“‹ éªŒè¯æŒ‡æ ‡:")
    print(f"    ğŸ¯ RÂ²: {val_metrics.get('R2', 0):.4f}")
    print(f"    ğŸ¯ KGE: {val_metrics.get('KGE', 0):.4f}")
    print(f"    ğŸ“Š RMSE: {val_metrics.get('RMSE', 0):.4f}")
    print(f"  â³ æœªæ”¹è¿›è®¡æ•°: {patience_counter}/{patience}")
